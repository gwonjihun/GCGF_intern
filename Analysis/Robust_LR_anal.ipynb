{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTNO</th>\n",
       "      <th>GNO</th>\n",
       "      <th>CBSCORE</th>\n",
       "      <th>CBSCOREGRD</th>\n",
       "      <th>CREDITOTAMT</th>\n",
       "      <th>YSALEAMT</th>\n",
       "      <th>ESTMM</th>\n",
       "      <th>ASSETAMT</th>\n",
       "      <th>IMSAAMT</th>\n",
       "      <th>IMJUAMT</th>\n",
       "      <th>...</th>\n",
       "      <th>환율</th>\n",
       "      <th>GDP</th>\n",
       "      <th>소상공인체감지수</th>\n",
       "      <th>실업률</th>\n",
       "      <th>물가지수</th>\n",
       "      <th>국고채</th>\n",
       "      <th>금리</th>\n",
       "      <th>유가등락률</th>\n",
       "      <th>소비자심리지수</th>\n",
       "      <th>ONEHOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>475821</td>\n",
       "      <td>l180202101898</td>\n",
       "      <td>1.015873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>10.743169</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>1.885958</td>\n",
       "      <td>51.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.724868</td>\n",
       "      <td>-1.256410</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.750600</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74417</td>\n",
       "      <td>l230201700120</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>2</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>6.027322</td>\n",
       "      <td>-0.380282</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537170</td>\n",
       "      <td>-0.901805</td>\n",
       "      <td>53.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.640212</td>\n",
       "      <td>-0.307692</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.100719</td>\n",
       "      <td>-0.596491</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387787</td>\n",
       "      <td>l110201603233</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282051</td>\n",
       "      <td>3.775956</td>\n",
       "      <td>2.098592</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>-1.182547</td>\n",
       "      <td>72.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.417989</td>\n",
       "      <td>-0.461538</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.110312</td>\n",
       "      <td>-0.482456</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>395418</td>\n",
       "      <td>l230201700254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>3.562842</td>\n",
       "      <td>-0.352113</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520384</td>\n",
       "      <td>-0.901805</td>\n",
       "      <td>76.2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.677249</td>\n",
       "      <td>-0.205128</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.429257</td>\n",
       "      <td>-0.394737</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190372</td>\n",
       "      <td>l200201601418</td>\n",
       "      <td>-2.476190</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>1.437158</td>\n",
       "      <td>1.845070</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446043</td>\n",
       "      <td>-1.357134</td>\n",
       "      <td>63.2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.867725</td>\n",
       "      <td>-1.461538</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.618705</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CUSTNO            GNO   CBSCORE  CBSCOREGRD  CREDITOTAMT   YSALEAMT  \\\n",
       "0  475821  l180202101898  1.015873           1     0.230769  10.743169   \n",
       "1   74417  l230201700120  0.206349           2     0.205128   6.027322   \n",
       "2  387787  l110201603233  0.396825           1    -0.282051   3.775956   \n",
       "3  395418  l230201700254  0.000000           2     0.076923   3.562842   \n",
       "4  190372  l200201601418 -2.476190           6    -0.102564   1.437158   \n",
       "\n",
       "      ESTMM  ASSETAMT  IMSAAMT  IMJUAMT  ...        환율       GDP  소상공인체감지수  \\\n",
       "0  0.014085        10      0.0      0.0  ...  0.009592  1.885958      51.4   \n",
       "1 -0.380282        25     -0.5     25.0  ...  0.537170 -0.901805      53.8   \n",
       "2  2.098592        10      0.0      0.0  ...  0.978417 -1.182547      72.6   \n",
       "3 -0.352113        10      0.0      0.0  ...  0.520384 -0.901805      76.2   \n",
       "4  1.845070        80     -0.4      0.0  ...  0.446043 -1.357134      63.2   \n",
       "\n",
       "        실업률      물가지수       국고채   금리     유가등락률   소비자심리지수  ONEHOT  \n",
       "0  0.000000  1.724868 -1.256410 -4.0  1.750600  0.798246       3  \n",
       "1  0.666667 -0.640212 -0.307692 -1.0  1.100719 -0.596491       8  \n",
       "2  0.000000 -1.417989 -0.461538 -1.0  0.110312 -0.482456       7  \n",
       "3 -0.333333 -0.677249 -0.205128 -1.0  0.429257 -0.394737       3  \n",
       "4 -0.333333 -1.867725 -1.461538 -1.0 -0.618705 -0.017544       7  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = pd.read_csv(\"DATA/Robust_Scaler_result.csv\",encoding=\"cp949\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>ACTCD</td>      <th>  R-squared:         </th> <td>   0.061</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.060</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   168.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 07 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:16:26</td>     <th>  Log-Likelihood:    </th> <td> -5568.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 39117</td>      <th>  AIC:               </th> <td>1.117e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 39101</td>      <th>  BIC:               </th> <td>1.131e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>   <td>    0.1210</td> <td>    0.004</td> <td>   33.184</td> <td> 0.000</td> <td>    0.114</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CBSCORE</th>     <td>   -0.0621</td> <td>    0.002</td> <td>  -29.323</td> <td> 0.000</td> <td>   -0.066</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CREDITOTAMT</th> <td>    0.0011</td> <td>    0.000</td> <td>    3.881</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YSALEAMT</th>    <td>    0.0046</td> <td>    0.001</td> <td>    5.256</td> <td> 0.000</td> <td>    0.003</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ESTMM</th>       <td>   -0.0245</td> <td>    0.002</td> <td>  -15.021</td> <td> 0.000</td> <td>   -0.028</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMSAAMT</th>     <td>   -0.0012</td> <td>    0.001</td> <td>   -1.921</td> <td> 0.055</td> <td>   -0.002</td> <td> 2.46e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMJUAMT</th>     <td>   -0.0001</td> <td> 2.16e-05</td> <td>   -5.954</td> <td> 0.000</td> <td>   -0.000</td> <td>-8.64e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BUJUAMT</th>     <td>   -0.0001</td> <td> 1.01e-05</td> <td>  -10.416</td> <td> 0.000</td> <td>   -0.000</td> <td>-8.58e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BU1TOTAMT</th>   <td>    0.0007</td> <td>    0.000</td> <td>    3.207</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GAMT</th>        <td>   -0.0080</td> <td>    0.002</td> <td>   -3.971</td> <td> 0.000</td> <td>   -0.012</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GKIND</th>       <td>    0.0046</td> <td>    0.002</td> <td>    2.757</td> <td> 0.006</td> <td>    0.001</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>환율</th>          <td>    0.0064</td> <td>    0.003</td> <td>    2.544</td> <td> 0.011</td> <td>    0.001</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GDP</th>         <td>   -0.0319</td> <td>    0.002</td> <td>  -16.951</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>국고채</th>         <td>    0.0115</td> <td>    0.003</td> <td>    3.973</td> <td> 0.000</td> <td>    0.006</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>유가등락률</th>       <td>    0.0071</td> <td>    0.003</td> <td>    2.820</td> <td> 0.005</td> <td>    0.002</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ONEHOT</th>      <td>   -0.0025</td> <td>    0.000</td> <td>   -7.785</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19693.786</td> <th>  Durbin-Watson:     </th> <td>   1.719</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>90089.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.581</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 8.351</td>   <th>  Cond. No.          </th> <td>    425.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  ACTCD   R-squared:                       0.061\n",
       "Model:                            OLS   Adj. R-squared:                  0.060\n",
       "Method:                 Least Squares   F-statistic:                     168.1\n",
       "Date:                Tue, 07 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:16:26   Log-Likelihood:                -5568.3\n",
       "No. Observations:               39117   AIC:                         1.117e+04\n",
       "Df Residuals:                   39101   BIC:                         1.131e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "intercept       0.1210      0.004     33.184      0.000       0.114       0.128\n",
       "CBSCORE        -0.0621      0.002    -29.323      0.000      -0.066      -0.058\n",
       "CREDITOTAMT     0.0011      0.000      3.881      0.000       0.001       0.002\n",
       "YSALEAMT        0.0046      0.001      5.256      0.000       0.003       0.006\n",
       "ESTMM          -0.0245      0.002    -15.021      0.000      -0.028      -0.021\n",
       "IMSAAMT        -0.0012      0.001     -1.921      0.055      -0.002    2.46e-05\n",
       "IMJUAMT        -0.0001   2.16e-05     -5.954      0.000      -0.000   -8.64e-05\n",
       "BUJUAMT        -0.0001   1.01e-05    -10.416      0.000      -0.000   -8.58e-05\n",
       "BU1TOTAMT       0.0007      0.000      3.207      0.001       0.000       0.001\n",
       "GAMT           -0.0080      0.002     -3.971      0.000      -0.012      -0.004\n",
       "GKIND           0.0046      0.002      2.757      0.006       0.001       0.008\n",
       "환율              0.0064      0.003      2.544      0.011       0.001       0.011\n",
       "GDP            -0.0319      0.002    -16.951      0.000      -0.036      -0.028\n",
       "국고채             0.0115      0.003      3.973      0.000       0.006       0.017\n",
       "유가등락률           0.0071      0.003      2.820      0.005       0.002       0.012\n",
       "ONEHOT         -0.0025      0.000     -7.785      0.000      -0.003      -0.002\n",
       "==============================================================================\n",
       "Omnibus:                    19693.786   Durbin-Watson:                   1.719\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            90089.052\n",
       "Skew:                           2.581   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.351   Cond. No.                         425.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['intercept'] = 1\n",
    "\n",
    "lm = sm.OLS(data['ACTCD'], data[[ 'intercept', 'CBSCORE', 'CREDITOTAMT', 'YSALEAMT',\n",
    "       'ESTMM', 'IMSAAMT', 'IMJUAMT',  'BUJUAMT',\n",
    "       'BU1TOTAMT', 'GAMT', 'GKIND',  '환율', 'GDP', \n",
    "        '국고채', '유가등락률', 'ONEHOT']]) \n",
    "results = lm.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['CBSCORE', 'CREDITOTAMT', 'YSALEAMT',\n",
    "       'ESTMM',  'IMSAAMT', 'IMJUAMT', 'BUSAAMT', 'BUJUAMT',\n",
    "       'BU1TOTAMT', 'GAMT', 'LABORCNT', 'KOSPI', '환율', 'GDP', \n",
    "       '소상공인체감지수', '실업률', '물가지수', '국고채', '금리', '유가등락률',\n",
    "       '소비자심리지수','ONEHOT']]\n",
    "act = data['ACTCD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = act - 1\n",
    "act = act * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27381, 22) (11736, 22) (27381,) (11736,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x,train_y, test_y = train_test_split(features, act,\n",
    "stratify=act,train_size=0.7,test_size=0.3,random_state=1)\n",
    "\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "#언더 샘플링\n",
    "enn = EditedNearestNeighbours(kind_sel=\"all\", n_neighbors=10)\n",
    "tomekl = TomekLinks()\n",
    "\n",
    "#오버 샘플링\n",
    "bsmote = BorderlineSMOTE(random_state=42)\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "#혼합 샘플링\n",
    "smotee = SMOTEENN(random_state=42)\n",
    "smoteT = SMOTETomek(random_state=42)\n",
    "\n",
    "\n",
    "X_under1_train, Y_under1_train = enn.fit_resample(train_x, train_y)\n",
    "X_under2_train, Y_under2_train = tomekl.fit_resample(train_x, train_y)\n",
    "\n",
    "X_over1_train, Y_over1_train = bsmote.fit_resample(train_x,train_y)\n",
    "X_over2_train, Y_over2_train = adasyn.fit_resample(train_x,train_y)\n",
    "\n",
    "X_comb1_train, Y_comb1_train = smotee.fit_resample(train_x, train_y)\n",
    "X_comb2_train, Y_comb2_train = smoteT.fit_resample(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래 분석 결과, Logistic Regression 하이퍼 파라미터: C와 max_iter 조정 결과 변화 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오버샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 함수\n",
    "\n",
    "def cut_off(y, threshold) :\n",
    "    Y = y.copy()  # 대문자 Y를 새로운 변수로 하여 기존의 y값에 영향이 가지 않도록 한다.\n",
    "    Y[Y>threshold] = 1\n",
    "    Y[Y<threshold] = 0\n",
    "    return Y.astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# confusion matrix accuracy(정확도) 계산함수\n",
    "\n",
    "def acc(cfmat):\n",
    "    return (cfmat[0,0] + cfmat[1,1])/(cfmat[0,0] + cfmat[1,1] + cfmat[0,1] + cfmat[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554386\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554386\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554386\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554386\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_over1_train,Y_over1_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_over1_train,X_over1_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555517\n",
      "         Iterations 6\n",
      "[[ 716  354]\n",
      " [3272 7394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사고보증       0.18      0.67      0.28      1070\n",
      "        정상보증       0.95      0.69      0.80     10666\n",
      "\n",
      "    accuracy                           0.69     11736\n",
      "   macro avg       0.57      0.68      0.54     11736\n",
      "weighted avg       0.88      0.69      0.76     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "results = model.fit(X_over1_train,Y_over1_train)\n",
    "model = sm.Logit(Y_over1_train,X_over1_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['사고보증', '정상보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1000, 0.6936775732788003, array([[7436, 3230],\n",
      "       [ 365,  705]], dtype=int64), 0.17916137229987295, 0.6588785046728972, 0.2817182817182817, 0.7471268210104254), (1500, 0.6936775732788003, array([[7436, 3230],\n",
      "       [ 365,  705]], dtype=int64), 0.17916137229987295, 0.6588785046728972, 0.2817182817182817, 0.7471268210104254), (2000, 0.6936775732788003, array([[7436, 3230],\n",
      "       [ 365,  705]], dtype=int64), 0.17916137229987295, 0.6588785046728972, 0.2817182817182817, 0.7471268210104254), (2500, 0.6936775732788003, array([[7436, 3230],\n",
      "       [ 365,  705]], dtype=int64), 0.17916137229987295, 0.6588785046728972, 0.2817182817182817, 0.7471268210104254), (3000, 0.6936775732788003, array([[7436, 3230],\n",
      "       [ 365,  705]], dtype=int64), 0.17916137229987295, 0.6588785046728972, 0.2817182817182817, 0.7471268210104254)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591397\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591397\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591397\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591397\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_over2_train,Y_over2_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_over2_train,X_over2_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588906\n",
      "         Iterations 6\n",
      "[[ 732  338]\n",
      " [3552 7114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사고보증       0.17      0.68      0.27      1070\n",
      "        정상보증       0.95      0.67      0.79     10666\n",
      "\n",
      "    accuracy                           0.67     11736\n",
      "   macro avg       0.56      0.68      0.53     11736\n",
      "weighted avg       0.88      0.67      0.74     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "results = model.fit(X_over2_train,Y_over2_train)\n",
    "model = sm.Logit(Y_over2_train,X_over2_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['사고보증', '정상보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1500, 0.6672631220177232, array([[7091, 3575],\n",
      "       [ 330,  740]], dtype=int64), 0.17149478563151796, 0.6915887850467289, 0.2748375116063138, 0.7440497887426375), (2000, 0.6672631220177232, array([[7091, 3575],\n",
      "       [ 330,  740]], dtype=int64), 0.17149478563151796, 0.6915887850467289, 0.2748375116063138, 0.7440497887426375), (2500, 0.6672631220177232, array([[7091, 3575],\n",
      "       [ 330,  740]], dtype=int64), 0.17149478563151796, 0.6915887850467289, 0.2748375116063138, 0.7440497887426375), (3000, 0.6672631220177232, array([[7091, 3575],\n",
      "       [ 330,  740]], dtype=int64), 0.17149478563151796, 0.6915887850467289, 0.2748375116063138, 0.7440497887426375)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언더샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347554\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347554\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347554\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347554\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347554\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in c:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = 1500, C = i)\n",
    "    results = model.fit(X_under1_train,Y_under1_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_under1_train,X_under1_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.351165\n",
      "         Iterations 8\n",
      "[[ 265  805]\n",
      " [ 751 9915]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사고보증       0.26      0.25      0.25      1070\n",
      "        정상보증       0.92      0.93      0.93     10666\n",
      "\n",
      "    accuracy                           0.87     11736\n",
      "   macro avg       0.59      0.59      0.59     11736\n",
      "weighted avg       0.86      0.87      0.87     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "results = model.fit(X_under1_train,Y_under1_train)\n",
    "model = sm.Logit(Y_under1_train,X_under1_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['사고보증', '정상보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, 0.8655419222903885, array([[9828,  838],\n",
      "       [ 740,  330]], dtype=int64), 0.2825342465753425, 0.308411214953271, 0.29490616621983917, 0.7460255839588105), (0.1, 0.8655419222903885, array([[9828,  838],\n",
      "       [ 740,  330]], dtype=int64), 0.2825342465753425, 0.308411214953271, 0.29490616621983917, 0.7460255839588105), (1, 0.8655419222903885, array([[9828,  838],\n",
      "       [ 740,  330]], dtype=int64), 0.2825342465753425, 0.308411214953271, 0.29490616621983917, 0.7460255839588105), (10, 0.8655419222903885, array([[9828,  838],\n",
      "       [ 740,  330]], dtype=int64), 0.2825342465753425, 0.308411214953271, 0.29490616621983917, 0.7460255839588105), (100, 0.8655419222903885, array([[9828,  838],\n",
      "       [ 740,  330]], dtype=int64), 0.2825342465753425, 0.308411214953271, 0.29490616621983917, 0.7460255839588105)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280166\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280166\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280166\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280166\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_under2_train,Y_under2_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_under2_train,X_under2_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280118\n",
      "         Iterations 8\n",
      "[[   15  1055]\n",
      " [   19 10647]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사고보증       0.44      0.01      0.03      1070\n",
      "        정상보증       0.91      1.00      0.95     10666\n",
      "\n",
      "    accuracy                           0.91     11736\n",
      "   macro avg       0.68      0.51      0.49     11736\n",
      "weighted avg       0.87      0.91      0.87     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "results = model.fit(X_under2_train,Y_under2_train)\n",
    "model = sm.Logit(Y_under2_train,X_under2_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['사고보증', '정상보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1500, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746), (2000, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746), (2500, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746), (3000, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746), (0.1, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746), (1, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746), (10, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746), (100, 0.9079754601226994, array([[10639,    27],\n",
      "       [ 1053,    17]], dtype=int64), 0.38636363636363635, 0.01588785046728972, 0.030520646319569116, 0.736720095823746)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 혼합 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516677\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516677\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516677\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516677\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516677\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in c:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = 1500, C = i)\n",
    "    results = model.fit(X_comb1_train,Y_comb1_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_comb1_train,X_comb1_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.513653\n",
      "         Iterations 7\n",
      "[[ 846  224]\n",
      " [4727 5939]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사고보증       0.15      0.79      0.25      1070\n",
      "        정상보증       0.96      0.56      0.71     10666\n",
      "\n",
      "    accuracy                           0.58     11736\n",
      "   macro avg       0.56      0.67      0.48     11736\n",
      "weighted avg       0.89      0.58      0.66     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "results = model.fit(X_comb1_train,Y_comb1_train)\n",
    "model = sm.Logit(Y_comb1_train,X_comb1_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['사고보증', '정상보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, 0.5720858895705522, array([[5855, 4811],\n",
      "       [ 211,  859]], dtype=int64), 0.15149911816578485, 0.802803738317757, 0.25489614243323444, 0.7482723073229459), (0.1, 0.5720858895705522, array([[5855, 4811],\n",
      "       [ 211,  859]], dtype=int64), 0.15149911816578485, 0.802803738317757, 0.25489614243323444, 0.7482723073229459), (1, 0.5720858895705522, array([[5855, 4811],\n",
      "       [ 211,  859]], dtype=int64), 0.15149911816578485, 0.802803738317757, 0.25489614243323444, 0.7482723073229459), (10, 0.5720858895705522, array([[5855, 4811],\n",
      "       [ 211,  859]], dtype=int64), 0.15149911816578485, 0.802803738317757, 0.25489614243323444, 0.7482723073229459), (100, 0.5720858895705522, array([[5855, 4811],\n",
      "       [ 211,  859]], dtype=int64), 0.15149911816578485, 0.802803738317757, 0.25489614243323444, 0.7482723073229459)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581883\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581883\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581883\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581883\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_comb2_train,Y_comb2_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_comb2_train,X_comb2_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.578177\n",
      "         Iterations 6\n",
      "[[ 723  347]\n",
      " [3429 7237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사고보증       0.17      0.68      0.28      1070\n",
      "        정상보증       0.95      0.68      0.79     10666\n",
      "\n",
      "    accuracy                           0.68     11736\n",
      "   macro avg       0.56      0.68      0.54     11736\n",
      "weighted avg       0.88      0.68      0.75     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "results = model.fit(X_comb2_train,Y_comb2_train)\n",
    "model = sm.Logit(Y_comb2_train,X_comb2_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['사고보증', '정상보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1500, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772), (2000, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772), (2500, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772), (3000, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772), (0.1, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772), (1, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772), (10, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772), (100, 0.6769768234492161, array([[7218, 3448],\n",
      "       [ 343,  727]], dtype=int64), 0.1741317365269461, 0.6794392523364486, 0.27721639656816016, 0.7454247578557772)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4000436974652e2da39f7abf97d4cef3d01362244b176d22af40d9d73df68d1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('Study_Big': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
