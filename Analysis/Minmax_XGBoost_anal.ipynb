{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DATA/MinMax_Scaler_result.csv\",encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['CBSCORE', 'CREDITOTAMT', 'YSALEAMT',\n",
    "       'ESTMM',  'IMSAAMT', 'IMJUAMT', 'BUSAAMT', 'BUJUAMT',\n",
    "       'BU1TOTAMT', 'GAMT', 'LABORCNT', 'KOSPI', '환율', 'GDP', \n",
    "       '소상공인체감지수', '실업률', '물가지수', '국고채', '금리', '유가등락률',\n",
    "       '소비자심리지수','ONEHOT']]\n",
    "act = data['ACTCD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27381, 22) (11736, 22) (27381,) (11736,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x,train_y, test_y = train_test_split(features, act,\n",
    "stratify=act,train_size=0.7,test_size=0.3,random_state=1)\n",
    "\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. ENN\n",
    "2. ADASYN\n",
    "3. BORDERLINE SMOTE\n",
    "4. Tomeklinks\n",
    "5 SOTEENN\n",
    "6.SMOTETOMEK\n",
    "'''\n",
    "from imblearn.over_sampling import BorderlineSMOTE,ADASYN\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks\n",
    "data_sets={}\n",
    "enn = EditedNearestNeighbours()\n",
    "ada = ADASYN(random_state=42)\n",
    "smte = SMOTEENN(random_state=42)\n",
    "smtt = SMOTETomek(random_state=42)\n",
    "tk = TomekLinks()\n",
    "sm = BorderlineSMOTE(random_state=42)\n",
    "enn_under_train_x,enn_under_train_y = enn.fit_resample(train_x,train_y)\n",
    "ada_over_train_x, ada_over_train_y = ada.fit_resample(train_x,train_y)\n",
    "smte_combine_train_x,smte_combine_train_y = smte.fit_resample(train_x,train_y)\n",
    "smtt_combine_train_x,smtt_combine_train_y = smtt.fit_resample(train_x,train_y)\n",
    "tk_under_train_x,tk_under_train_y = tk.fit_resample(train_x,train_y)\n",
    "sm_over_train_x, sm_over_train_y = sm.fit_resample(train_x,train_y)\n",
    "data_sets['enn']=[enn_under_train_x,enn_under_train_y]\n",
    "data_sets['ada']=[ada_over_train_x,ada_over_train_y]\n",
    "data_sets['smte']=[smte_combine_train_x,smte_combine_train_y]\n",
    "data_sets['smtt']=[smtt_combine_train_x,smtt_combine_train_y]\n",
    "data_sets['tk']=[tk_under_train_x,tk_under_train_y]\n",
    "data_sets['sm']=[sm_over_train_x,sm_over_train_y]\n",
    "'''\n",
    "over_train_x : 학습용 독립변수\n",
    "over_train_y : 학습용 종속변수\n",
    "'''\n",
    "keys_list= data_sets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019\n",
    ")\n",
    "\n",
    "xgb_param_gird = {\n",
    "    'n_estimators' : [100,500],\n",
    "    'learning_rate' : [0.01, 0.2],\n",
    "    'max_depth':[4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  20 out of  20 | elapsed:   30.1s finished\n",
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:19:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_delta_step=None,\n",
       "                                     max_depth=5, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=1000, n_jobs=None, nthread=-1,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=1,\n",
       "                                     seed=2019, subsample=0.8, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=3,\n",
       "             param_grid={'learning_rate': [0.01, 0.2], 'max_depth': [4],\n",
       "                         'n_estimators': [100, 500]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_gird = GridSearchCV(xgb,param_grid=xgb_param_gird, scoring=\"accuracy\",n_jobs=3,verbose=1)\n",
    "xgb_gird.fit(enn_under_train_x,enn_under_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4000436974652e2da39f7abf97d4cef3d01362244b176d22af40d9d73df68d1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('Study_Big': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
