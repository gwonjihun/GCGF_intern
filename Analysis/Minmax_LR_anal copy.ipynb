{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTNO</th>\n",
       "      <th>GNO</th>\n",
       "      <th>CBSCORE</th>\n",
       "      <th>CBSCOREGRD</th>\n",
       "      <th>CREDITOTAMT</th>\n",
       "      <th>YSALEAMT</th>\n",
       "      <th>ESTMM</th>\n",
       "      <th>ASSETAMT</th>\n",
       "      <th>IMSAAMT</th>\n",
       "      <th>IMJUAMT</th>\n",
       "      <th>...</th>\n",
       "      <th>환율</th>\n",
       "      <th>GDP</th>\n",
       "      <th>소상공인체감지수</th>\n",
       "      <th>실업률</th>\n",
       "      <th>물가지수</th>\n",
       "      <th>국고채</th>\n",
       "      <th>금리</th>\n",
       "      <th>유가등락률</th>\n",
       "      <th>소비자심리지수</th>\n",
       "      <th>ONEHOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>475821</td>\n",
       "      <td>l180202101898</td>\n",
       "      <td>0.949290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.223956</td>\n",
       "      <td>0.058085</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436398</td>\n",
       "      <td>0.989382</td>\n",
       "      <td>0.320660</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.928674</td>\n",
       "      <td>0.144172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.511688</td>\n",
       "      <td>0.956072</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74417</td>\n",
       "      <td>l230201700120</td>\n",
       "      <td>0.897566</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.129121</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518949</td>\n",
       "      <td>0.691828</td>\n",
       "      <td>0.355093</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.707266</td>\n",
       "      <td>0.257669</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.423701</td>\n",
       "      <td>0.545220</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387787</td>\n",
       "      <td>l110201603233</td>\n",
       "      <td>0.909736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083846</td>\n",
       "      <td>0.290424</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587992</td>\n",
       "      <td>0.661863</td>\n",
       "      <td>0.624821</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.634454</td>\n",
       "      <td>0.239264</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.289610</td>\n",
       "      <td>0.578811</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>395418</td>\n",
       "      <td>l230201700254</td>\n",
       "      <td>0.884381</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.079560</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516323</td>\n",
       "      <td>0.691828</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.703799</td>\n",
       "      <td>0.269939</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.332792</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190372</td>\n",
       "      <td>l200201601418</td>\n",
       "      <td>0.726166</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.036813</td>\n",
       "      <td>0.262166</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504690</td>\n",
       "      <td>0.643228</td>\n",
       "      <td>0.489957</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.592352</td>\n",
       "      <td>0.119632</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.190909</td>\n",
       "      <td>0.715762</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39112</th>\n",
       "      <td>514919</td>\n",
       "      <td>l240201902522</td>\n",
       "      <td>0.868154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555722</td>\n",
       "      <td>0.942670</td>\n",
       "      <td>0.528694</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.816237</td>\n",
       "      <td>0.171779</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.723514</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39113</th>\n",
       "      <td>357361</td>\n",
       "      <td>l160201601877</td>\n",
       "      <td>0.781947</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015699</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610507</td>\n",
       "      <td>0.628014</td>\n",
       "      <td>0.510043</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.601763</td>\n",
       "      <td>0.153374</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39114</th>\n",
       "      <td>340606</td>\n",
       "      <td>l270201900572</td>\n",
       "      <td>0.734280</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430394</td>\n",
       "      <td>0.851424</td>\n",
       "      <td>0.556671</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.785031</td>\n",
       "      <td>0.294479</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.702842</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39115</th>\n",
       "      <td>505207</td>\n",
       "      <td>l190201902523</td>\n",
       "      <td>0.952333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549719</td>\n",
       "      <td>0.942670</td>\n",
       "      <td>0.627690</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.803854</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.255844</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39116</th>\n",
       "      <td>498678</td>\n",
       "      <td>l110201903609</td>\n",
       "      <td>0.899594</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749343</td>\n",
       "      <td>0.899493</td>\n",
       "      <td>0.308465</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.800882</td>\n",
       "      <td>0.101227</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.160390</td>\n",
       "      <td>0.521964</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39117 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUSTNO            GNO   CBSCORE  CBSCOREGRD  CREDITOTAMT  YSALEAMT  \\\n",
       "0      475821  l180202101898  0.949290    0.000000     0.002338  0.223956   \n",
       "1       74417  l230201700120  0.897566    0.166667     0.002221  0.129121   \n",
       "2      387787  l110201603233  0.909736    0.000000     0.000000  0.083846   \n",
       "3      395418  l230201700254  0.884381    0.166667     0.001637  0.079560   \n",
       "4      190372  l200201601418  0.726166    0.833333     0.000818  0.036813   \n",
       "...       ...            ...       ...         ...          ...       ...   \n",
       "39112  514919  l240201902522  0.868154    0.333333     0.000000  0.000000   \n",
       "39113  357361  l160201601877  0.781947    0.666667     0.001286  0.000000   \n",
       "39114  340606  l270201900572  0.734280    0.833333     0.001052  0.000000   \n",
       "39115  505207  l190201902523  0.952333    0.000000     0.000000  0.000000   \n",
       "39116  498678  l110201903609  0.899594    0.166667     0.000585  0.000000   \n",
       "\n",
       "          ESTMM  ASSETAMT   IMSAAMT   IMJUAMT  ...        환율       GDP  \\\n",
       "0      0.058085  0.000768  0.004153  0.000000  ...  0.436398  0.989382   \n",
       "1      0.014129  0.001920  0.000000  0.015489  ...  0.518949  0.691828   \n",
       "2      0.290424  0.000768  0.004153  0.000000  ...  0.587992  0.661863   \n",
       "3      0.017268  0.000768  0.004153  0.000000  ...  0.516323  0.691828   \n",
       "4      0.262166  0.006143  0.000831  0.000000  ...  0.504690  0.643228   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "39112  0.018838  0.000000  0.000000  0.000000  ...  0.555722  0.942670   \n",
       "39113  0.015699  0.000768  0.000000  0.006196  ...  0.610507  0.628014   \n",
       "39114  0.072214  0.000000  0.000000  0.000000  ...  0.430394  0.851424   \n",
       "39115  0.007849  0.000000  0.000000  0.000000  ...  0.549719  0.942670   \n",
       "39116  0.025118  0.000461  0.002492  0.000000  ...  0.749343  0.899493   \n",
       "\n",
       "       소상공인체감지수       실업률      물가지수       국고채        금리     유가등락률   소비자심리지수  \\\n",
       "0      0.320660  0.346154  0.928674  0.144172  0.000000  0.511688  0.956072   \n",
       "1      0.355093  0.423077  0.707266  0.257669  0.272727  0.423701  0.545220   \n",
       "2      0.624821  0.346154  0.634454  0.239264  0.272727  0.289610  0.578811   \n",
       "3      0.676471  0.307692  0.703799  0.269939  0.272727  0.332792  0.604651   \n",
       "4      0.489957  0.307692  0.592352  0.119632  0.272727  0.190909  0.715762   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39112  0.528694  0.346154  0.816237  0.171779  0.272727  0.340909  0.723514   \n",
       "39113  0.510043  0.307692  0.601763  0.153374  0.272727  0.168182  0.658915   \n",
       "39114  0.556671  0.384615  0.785031  0.294479  0.454545  0.204870  0.702842   \n",
       "39115  0.627690  0.346154  0.803854  0.202454  0.272727  0.255844  0.733850   \n",
       "39116  0.308465  0.153846  0.800882  0.101227  0.363636  0.160390  0.521964   \n",
       "\n",
       "       ONEHOT  \n",
       "0           3  \n",
       "1           8  \n",
       "2           7  \n",
       "3           3  \n",
       "4           7  \n",
       "...       ...  \n",
       "39112       7  \n",
       "39113      16  \n",
       "39114      19  \n",
       "39115      16  \n",
       "39116       9  \n",
       "\n",
       "[39117 rows x 30 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = pd.read_csv(\"DATA/MinMax_Scaler_result.csv\",encoding=\"cp949\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>ACTCD</td>      <th>  R-squared:         </th> <td>   0.061</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.060</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   168.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 21 Dec 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:28:41</td>     <th>  Log-Likelihood:    </th> <td> -5568.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 39117</td>      <th>  AIC:               </th> <td>1.117e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 39101</td>      <th>  BIC:               </th> <td>1.131e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>   <td>    1.1724</td> <td>    0.035</td> <td>   33.832</td> <td> 0.000</td> <td>    1.104</td> <td>    1.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CBSCORE</th>     <td>   -0.9712</td> <td>    0.033</td> <td>  -29.323</td> <td> 0.000</td> <td>   -1.036</td> <td>   -0.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CREDITOTAMT</th> <td>    0.2505</td> <td>    0.065</td> <td>    3.881</td> <td> 0.000</td> <td>    0.124</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>YSALEAMT</th>    <td>    0.2275</td> <td>    0.043</td> <td>    5.256</td> <td> 0.000</td> <td>    0.143</td> <td>    0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ESTMM</th>       <td>   -0.2198</td> <td>    0.015</td> <td>  -15.021</td> <td> 0.000</td> <td>   -0.248</td> <td>   -0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMSAAMT</th>     <td>   -0.1458</td> <td>    0.076</td> <td>   -1.921</td> <td> 0.055</td> <td>   -0.294</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMJUAMT</th>     <td>   -0.2078</td> <td>    0.035</td> <td>   -5.954</td> <td> 0.000</td> <td>   -0.276</td> <td>   -0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BUJUAMT</th>     <td>   -0.5645</td> <td>    0.054</td> <td>  -10.416</td> <td> 0.000</td> <td>   -0.671</td> <td>   -0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BU1TOTAMT</th>   <td>    0.2021</td> <td>    0.063</td> <td>    3.207</td> <td> 0.001</td> <td>    0.079</td> <td>    0.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GAMT</th>        <td>   -0.0596</td> <td>    0.015</td> <td>   -3.971</td> <td> 0.000</td> <td>   -0.089</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GKIND</th>       <td>    0.0046</td> <td>    0.002</td> <td>    2.757</td> <td> 0.006</td> <td>    0.001</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>환율</th>          <td>    0.0411</td> <td>    0.016</td> <td>    2.544</td> <td> 0.011</td> <td>    0.009</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GDP</th>         <td>   -0.2986</td> <td>    0.018</td> <td>  -16.951</td> <td> 0.000</td> <td>   -0.333</td> <td>   -0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>국고채</th>         <td>    0.0965</td> <td>    0.024</td> <td>    3.973</td> <td> 0.000</td> <td>    0.049</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>유가등락률</th>       <td>    0.0522</td> <td>    0.019</td> <td>    2.820</td> <td> 0.005</td> <td>    0.016</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ONEHOT</th>      <td>   -0.0025</td> <td>    0.000</td> <td>   -7.785</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19693.786</td> <th>  Durbin-Watson:     </th> <td>   1.719</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>90089.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 2.581</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 8.351</td>   <th>  Cond. No.          </th> <td>    578.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  ACTCD   R-squared:                       0.061\n",
       "Model:                            OLS   Adj. R-squared:                  0.060\n",
       "Method:                 Least Squares   F-statistic:                     168.1\n",
       "Date:                Tue, 21 Dec 2021   Prob (F-statistic):               0.00\n",
       "Time:                        17:28:41   Log-Likelihood:                -5568.3\n",
       "No. Observations:               39117   AIC:                         1.117e+04\n",
       "Df Residuals:                   39101   BIC:                         1.131e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "intercept       1.1724      0.035     33.832      0.000       1.104       1.240\n",
       "CBSCORE        -0.9712      0.033    -29.323      0.000      -1.036      -0.906\n",
       "CREDITOTAMT     0.2505      0.065      3.881      0.000       0.124       0.377\n",
       "YSALEAMT        0.2275      0.043      5.256      0.000       0.143       0.312\n",
       "ESTMM          -0.2198      0.015    -15.021      0.000      -0.248      -0.191\n",
       "IMSAAMT        -0.1458      0.076     -1.921      0.055      -0.294       0.003\n",
       "IMJUAMT        -0.2078      0.035     -5.954      0.000      -0.276      -0.139\n",
       "BUJUAMT        -0.5645      0.054    -10.416      0.000      -0.671      -0.458\n",
       "BU1TOTAMT       0.2021      0.063      3.207      0.001       0.079       0.326\n",
       "GAMT           -0.0596      0.015     -3.971      0.000      -0.089      -0.030\n",
       "GKIND           0.0046      0.002      2.757      0.006       0.001       0.008\n",
       "환율              0.0411      0.016      2.544      0.011       0.009       0.073\n",
       "GDP            -0.2986      0.018    -16.951      0.000      -0.333      -0.264\n",
       "국고채             0.0965      0.024      3.973      0.000       0.049       0.144\n",
       "유가등락률           0.0522      0.019      2.820      0.005       0.016       0.089\n",
       "ONEHOT         -0.0025      0.000     -7.785      0.000      -0.003      -0.002\n",
       "==============================================================================\n",
       "Omnibus:                    19693.786   Durbin-Watson:                   1.719\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            90089.052\n",
       "Skew:                           2.581   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.351   Cond. No.                         578.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['intercept'] = 1\n",
    "\n",
    "lm = sm.OLS(data['ACTCD'], data[[ 'intercept', 'CBSCORE', 'CREDITOTAMT', 'YSALEAMT',\n",
    "       'ESTMM', 'IMSAAMT', 'IMJUAMT',  'BUJUAMT',\n",
    "       'BU1TOTAMT', 'GAMT', 'GKIND',  '환율', 'GDP', \n",
    "        '국고채', '유가등락률', 'ONEHOT']]) \n",
    "results = lm.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['CBSCORE', 'CREDITOTAMT', 'YSALEAMT',\n",
    "       'ESTMM',  'IMSAAMT', 'IMJUAMT', 'BUSAAMT', 'BUJUAMT',\n",
    "       'BU1TOTAMT', 'GAMT', 'LABORCNT', 'KOSPI', '환율', 'GDP', \n",
    "       '소상공인체감지수', '실업률', '물가지수', '국고채', '금리', '유가등락률',\n",
    "       '소비자심리지수','ONEHOT']]\n",
    "act = data['ACTCD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = act - 1\n",
    "act = act * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27381, 22) (11736, 22) (27381,) (11736,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x,train_y, test_y = train_test_split(features, act,\n",
    "stratify=act,train_size=0.7,test_size=0.3,random_state=1)\n",
    "\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "#언더 샘플링\n",
    "enn = EditedNearestNeighbours(kind_sel=\"all\", n_neighbors=10)\n",
    "tomekl = TomekLinks()\n",
    "\n",
    "#오버 샘플링\n",
    "bsmote = BorderlineSMOTE(random_state=42)\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "#혼합 샘플링\n",
    "smotee = SMOTEENN(random_state=42)\n",
    "smoteT = SMOTETomek(random_state=42)\n",
    "\n",
    "\n",
    "X_under1_train, Y_under1_train = enn.fit_resample(train_x, train_y)\n",
    "X_under2_train, Y_under2_train = tomekl.fit_resample(train_x, train_y)\n",
    "\n",
    "X_over1_train, Y_over1_train = bsmote.fit_resample(train_x,train_y)\n",
    "X_over2_train, Y_over2_train = adasyn.fit_resample(train_x,train_y)\n",
    "\n",
    "X_comb1_train, Y_comb1_train = smotee.fit_resample(train_x, train_y)\n",
    "X_comb2_train, Y_comb2_train = smoteT.fit_resample(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래 분석 결과, Logistic Regression 하이퍼 파라미터: C와 max_iter 조정 결과 변화 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오버샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임계값 함수\n",
    "\n",
    "def cut_off(y, threshold) :\n",
    "    Y = y.copy()  # 대문자 Y를 새로운 변수로 하여 기존의 y값에 영향이 가지 않도록 한다.\n",
    "    Y[Y>threshold] = 1\n",
    "    Y[Y<threshold] = 0\n",
    "    return Y.astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# confusion matrix accuracy(정확도) 계산함수\n",
    "\n",
    "def acc(cfmat):\n",
    "    return (cfmat[0,0] + cfmat[1,1])/(cfmat[0,0] + cfmat[1,1] + cfmat[0,1] + cfmat[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580541\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580541\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580541\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580541\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580541\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in c:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = 1000, C = i)\n",
    "    results = model.fit(X_over1_train,Y_over1_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_over1_train,X_over1_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6975, 3691],\n",
       "       [ 339,  731]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, 0.6566121336059987, array([[6975, 3691],\n",
      "       [ 339,  731]], dtype=int64), 0.1653098145635459, 0.6831775700934579, 0.2662053896576839, 0.7219815870501252), (0.1, 0.6566121336059987, array([[6975, 3691],\n",
      "       [ 339,  731]], dtype=int64), 0.1653098145635459, 0.6831775700934579, 0.2662053896576839, 0.7219815870501252), (1, 0.6566121336059987, array([[6975, 3691],\n",
      "       [ 339,  731]], dtype=int64), 0.1653098145635459, 0.6831775700934579, 0.2662053896576839, 0.7219815870501252), (10, 0.6566121336059987, array([[6975, 3691],\n",
      "       [ 339,  731]], dtype=int64), 0.1653098145635459, 0.6831775700934579, 0.2662053896576839, 0.7219815870501252), (100, 0.6566121336059987, array([[6975, 3691],\n",
      "       [ 339,  731]], dtype=int64), 0.1653098145635459, 0.6831775700934579, 0.2662053896576839, 0.7219815870501252)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.577088\n",
      "         Iterations 7\n",
      "[[ 707  363]\n",
      " [3691 6975]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사고보증       0.16      0.66      0.26      1070\n",
      "        정상보증       0.95      0.65      0.77     10666\n",
      "\n",
      "    accuracy                           0.65     11736\n",
      "   macro avg       0.56      0.66      0.52     11736\n",
      "weighted avg       0.88      0.65      0.73     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "results = model.fit(X_over1_train,Y_over1_train)\n",
    "model = sm.Logit(Y_over1_train,X_over1_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['사고보증', '정상보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580541\n",
      "         Iterations 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사고보증       0.95      0.65      0.78     10666\n",
      "        정상보증       0.17      0.68      0.27      1070\n",
      "\n",
      "    accuracy                           0.66     11736\n",
      "   macro avg       0.56      0.67      0.52     11736\n",
      "weighted avg       0.88      0.66      0.73     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "results = model.fit(X_over1_train,Y_over1_train)\n",
    "model = sm.Logit(Y_over1_train,X_over1_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "print(classification_report(test_y, pred_Y, target_names=['사고보증', '정상보증']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.614539\n",
      "         Iterations 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_over2_train,Y_over2_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_over2_train,X_over2_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.609770\n",
      "         Iterations 7\n",
      "[[ 749  321]\n",
      " [4007 6659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        정상보증       0.16      0.70      0.26      1070\n",
      "        사고보증       0.95      0.62      0.75     10666\n",
      "\n",
      "    accuracy                           0.63     11736\n",
      "   macro avg       0.56      0.66      0.51     11736\n",
      "weighted avg       0.88      0.63      0.71     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "results = model.fit(X_over2_train,Y_over2_train)\n",
    "model = sm.Logit(Y_over2_train,X_over2_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['정상보증', '사고보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35620    0.508215\n",
      "13304    0.460507\n",
      "38803    0.695367\n",
      "8618     0.419623\n",
      "36794    0.681233\n",
      "           ...   \n",
      "4064     0.402090\n",
      "7401     0.154333\n",
      "28336    0.098065\n",
      "34226    0.365622\n",
      "22837    0.084831\n",
      "Length: 11736, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언더샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.349382\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.349382\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.349382\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.349382\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_under1_train,Y_under1_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_under1_train,X_under1_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.354080\n",
      "         Iterations 8\n",
      "[[ 224  846]\n",
      " [ 710 9956]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        정상보증       0.24      0.21      0.22      1070\n",
      "        사고보증       0.92      0.93      0.93     10666\n",
      "\n",
      "    accuracy                           0.87     11736\n",
      "   macro avg       0.58      0.57      0.58     11736\n",
      "weighted avg       0.86      0.87      0.86     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "results = model.fit(X_under1_train,Y_under1_train)\n",
    "model = sm.Logit(Y_under1_train,X_under1_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['정상보증', '사고보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1500, 0.8712508520790729, array([[10002,   664],\n",
      "       [  847,   223]], dtype=int64), 0.25140924464487036, 0.20841121495327103, 0.227899846704139, 0.7237181733905098), (2000, 0.8712508520790729, array([[10002,   664],\n",
      "       [  847,   223]], dtype=int64), 0.25140924464487036, 0.20841121495327103, 0.227899846704139, 0.7237181733905098), (2500, 0.8712508520790729, array([[10002,   664],\n",
      "       [  847,   223]], dtype=int64), 0.25140924464487036, 0.20841121495327103, 0.227899846704139, 0.7237181733905098), (3000, 0.8712508520790729, array([[10002,   664],\n",
      "       [  847,   223]], dtype=int64), 0.25140924464487036, 0.20841121495327103, 0.227899846704139, 0.7237181733905098)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282019\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282019\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282019\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.282019\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_under2_train,Y_under2_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_under2_train,X_under2_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.281413\n",
      "         Iterations 8\n",
      "[[    2  1068]\n",
      " [    9 10657]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        정상보증       0.18      0.00      0.00      1070\n",
      "        사고보증       0.91      1.00      0.95     10666\n",
      "\n",
      "    accuracy                           0.91     11736\n",
      "   macro avg       0.55      0.50      0.48     11736\n",
      "weighted avg       0.84      0.91      0.87     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "results = model.fit(X_under2_train,Y_under2_train)\n",
    "model = sm.Logit(Y_under2_train,X_under2_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['정상보증', '사고보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1500, 0.9080606680299932, array([[10653,    13],\n",
      "       [ 1066,     4]], dtype=int64), 0.23529411764705882, 0.003738317757009346, 0.00735970561177553, 0.7321097609488445), (2000, 0.9080606680299932, array([[10653,    13],\n",
      "       [ 1066,     4]], dtype=int64), 0.23529411764705882, 0.003738317757009346, 0.00735970561177553, 0.7321097609488445), (2500, 0.9080606680299932, array([[10653,    13],\n",
      "       [ 1066,     4]], dtype=int64), 0.23529411764705882, 0.003738317757009346, 0.00735970561177553, 0.7321097609488445), (3000, 0.9080606680299932, array([[10653,    13],\n",
      "       [ 1066,     4]], dtype=int64), 0.23529411764705882, 0.003738317757009346, 0.00735970561177553, 0.7321097609488445)]\n"
     ]
    }
   ],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 혼합 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_comb1_train,Y_comb1_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_comb1_train,X_comb1_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535031\n",
      "         Iterations 7\n",
      "[[ 864  206]\n",
      " [5429 5237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        정상보증       0.14      0.81      0.23      1070\n",
      "        사고보증       0.96      0.49      0.65     10666\n",
      "\n",
      "    accuracy                           0.52     11736\n",
      "   macro avg       0.55      0.65      0.44     11736\n",
      "weighted avg       0.89      0.52      0.61     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "results = model.fit(X_comb1_train,Y_comb1_train)\n",
    "model = sm.Logit(Y_comb1_train,X_comb1_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['정상보증', '사고보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anal_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. SMOTE Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "anal_result = []\n",
    "m = [1500, 2000, 2500, 3000]\n",
    "c = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i in m:\n",
    "    model = LogisticRegression(random_state = 42, solver = 'lbfgs', max_iter = i)\n",
    "    results = model.fit(X_comb2_train,Y_comb2_train)\n",
    "    \n",
    "    #로지스틱 모형 적합\n",
    "    model = sm.Logit(Y_comb2_train,X_comb2_train)\n",
    "    results = model.fit()\n",
    "\n",
    "    pred_y = results.predict(test_x)\n",
    "    pred_Y = cut_off(pred_y, 0.5)\n",
    "\n",
    "    cfmat = confusion_matrix(test_y,pred_Y)\n",
    "    accuracy = acc(cfmat)\n",
    "\n",
    "    pr = precision_score(test_y,pred_Y)\n",
    "    r = recall_score(test_y,pred_Y)\n",
    "    f1= f1_score(test_y,pred_Y)\n",
    "    auc_score = roc_auc_score(test_y,pred_y)\n",
    "    \n",
    "    anal_result.append((i, accuracy, cfmat, pr, r, f1, auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.600568\n",
      "         Iterations 7\n",
      "[[ 737  333]\n",
      " [3906 6760]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        정상보증       0.16      0.69      0.26      1070\n",
      "        사고보증       0.95      0.63      0.76     10666\n",
      "\n",
      "    accuracy                           0.64     11736\n",
      "   macro avg       0.56      0.66      0.51     11736\n",
      "weighted avg       0.88      0.64      0.72     11736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\Study_Big\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "results = model.fit(X_comb2_train,Y_comb2_train)\n",
    "model = sm.Logit(Y_comb2_train,X_comb2_train)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(test_x)\n",
    "pred_Y = cut_off(pred_y, 0.5)\n",
    "cfmat = confusion_matrix(test_y,pred_Y)\n",
    "print(cfmat)\n",
    "print(classification_report(test_y, pred_Y, target_names=['정상보증', '사고보증']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anal_result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4000436974652e2da39f7abf97d4cef3d01362244b176d22af40d9d73df68d1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('Study_Big': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
